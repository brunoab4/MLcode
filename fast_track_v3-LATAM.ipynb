{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### LATAM QMS : Fast Track Module\n",
    "##### Run quality / fraud queries on presto and tag / note courier partners\n",
    "###### Runs 2 times a day (0900, 1600 hrs MEXICO TIME) translates into 1500, 2300 hrs UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eats LATAM QMS : Fast Track\n",
    "# @ bhama@uber.com, shane.macnamara@uber.com\n",
    "\n",
    "# authorize Fast Track Actions Control Center (global)\n",
    "\n",
    "import pygsheets\n",
    "import unidecode\n",
    "\n",
    "root_dir = '/home/udocker/brunoa/Fast-Track'\n",
    "path_to_google_json = os.path.join(root_dir,'client_secret.json')\n",
    "gc = pygsheets.authorize(outh_file=path_to_google_json, outh_nonlocal=True)\n",
    "# gsheet_name = 'LatAm Fast-Track - Actions Control Center'\n",
    "gsheet_key = '1FvqZ0mmLtaTmJ1xOUFHCUU3F1nPLkMofand0FK6TFPk'\n",
    "# gs = gc.open(gsheet_name)\n",
    "gs = gc.open_by_key(gsheet_key)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "notification_tracking_tag = 'latam_fraud_fasttrack_soft_tag'\n",
    "waitlist_tracking_tag = 'latam_fraud_fasttrack_wl_queue'\n",
    "\n",
    "# initializing populous services\n",
    "from tchannel import thrift \n",
    "from tchannel.sync import TChannel\n",
    "import ujson \n",
    "with open(\"/etc/uber/hyperbahn/hosts.json\") as f:\n",
    "    known_peers = ujson.load(f)\n",
    "global tchannel \n",
    "tchannel = TChannel(name=\"tcurl\", known_peers=known_peers)\n",
    "global populous_service\n",
    "populous_service= thrift.load(path=\"/home/udocker/brunoa/Fast-Track/populous.thrift\", service=\"populous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df(element):\n",
    "    try:\n",
    "        if (element.isspace() or element == ''):\n",
    "            return ''\n",
    "        if isinstance(element, basestring):\n",
    "            try :\n",
    "                return unidecode.unidecode(element)\n",
    "            except UnicodeDecodeError:\n",
    "                return element.decode('latin1')\n",
    "    except AttributeError:\n",
    "        return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if fast track is switched off\n",
    "def is_fast_track():\n",
    "    \n",
    "    ws_name = 'locked_actions'\n",
    "\n",
    "    # open worksheet and load settings\n",
    "    ws = gs.worksheet_by_title(ws_name)\n",
    "    t1 = ws.cell('C1').value\n",
    "    \n",
    "    if t1 == 'Run Fast Track':\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local function to call saved queries from queryrunner_client \n",
    "def saved_query(query,database,datestr,rules,city_ids):\n",
    "    from queryrunner_client import Client\n",
    "    q = Client(user_email = 'brunoa@uber.com')\n",
    "    param = {'rule_list': rules, 'datestr': datestr, 'city_ids': str(city_ids)}\n",
    "    e = q.execute_report(query, parameters = param)\n",
    "    d = e.fetchall()\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query runner engine for building parameters and executing query\n",
    "def qb_engine(df,query,database,datestr):\n",
    "    \n",
    "    try:\n",
    "        # exception : No cities enabled for fast track, exit\n",
    "        if (df.shape[0] <> 0):\n",
    "\n",
    "            # initiate query parameters for query_1\n",
    "            rules = \"select 0 as city_id,'rule_name' as rule_name, 0 as threshold, 0 as lookback_period\"\n",
    "            city_ids = ''\n",
    "\n",
    "            # exception : Only one city enabled in fast track \n",
    "            if (df['City ID'].unique().shape[0] == 1):\n",
    "\n",
    "                # create city_ids and rules for one city \n",
    "                city_ids = str(df['City ID'].unique()[0])\n",
    "                for index,row in df.iterrows():\n",
    "                    rules += \" union select \"+str(row['City ID'])+ \", '\"+str(row['Rule'])+\"', \"+str(row['Threshold'])+\", \"+str(row['Lookback'])\n",
    "\n",
    "                rd = saved_query(query,database,datestr,rules,city_ids)\n",
    "\n",
    "            else:\n",
    "\n",
    "                # create city_ids and rules for multiple cities\n",
    "                city_ids = ','.join(map(str,df['City ID'].unique()))\n",
    "                for index,row in df.iterrows():\n",
    "                    rules += \" union select \"+str(row['City ID'])+ \", '\"+str(row['Rule'])+\"', \"+str(row['Threshold'])+\", \"+str(row['Lookback'])\n",
    "\n",
    "                rd = saved_query(query,database,datestr,rules,city_ids)\n",
    "                \n",
    "    except:\n",
    "        rd = 'Failed Run'\n",
    "    \n",
    "    return rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cool off and query runner engine for building parameters and executing cool off logic\n",
    "def co_engine(df,query,database,datestr):\n",
    "    \n",
    "    try:  \n",
    "        # separating the dataframe by rule group \" notification\"\n",
    "        df_n = df[df['Rule'].str.contains(\"notification\")]\n",
    "\n",
    "        # build the cool down parameters\n",
    "        df_c = pd.DataFrame(columns=['City ID','Lookback'])\n",
    "\n",
    "        for ctr in range(0,len(df_n['City ID'].unique())):\n",
    "            df_c = df_c.append({'City ID':str(df_n['City ID'].unique()[ctr]),'Lookback':str(df_n[df_n['City ID'] == df_n['City ID'].unique()[ctr]]['Lookback'].max())},ignore_index=True)\n",
    "\n",
    "        # Cooloff logic to exclude the couriers \n",
    "        # from the actioning process \n",
    "\n",
    "        if (df_c.shape[0] <> 0):\n",
    "\n",
    "            # initiate query parameters for cooldown\n",
    "            rules = \"select 0 as city_id, 0 as lookback_period\"\n",
    "            city_ids = ''\n",
    "\n",
    "            # exception : Only one city enabled in fast track \n",
    "            if (df_c.shape[0] == 1):\n",
    "\n",
    "                # create city_ids and rules for one city \n",
    "                city_ids = str(df_c['City ID'][0])\n",
    "                for index,row in df_c.iterrows():\n",
    "                    rules += \" union select \"+str(row['City ID'])+ \", \"+str(row['Lookback'])\n",
    "\n",
    "                rd = saved_query(query,database,datestr,rules,city_ids)\n",
    "\n",
    "            else:\n",
    "\n",
    "                # create city_ids and rules for multiple cities\n",
    "                city_ids = ','.join(map(str,df_c['City ID'].unique()))\n",
    "                for index,row in df_c.iterrows():\n",
    "                    rules += \" union select \"+str(row['City ID'])+ \", \"+str(row['Lookback'])\n",
    "\n",
    "                rd = saved_query(query,database,datestr,rules,city_ids)\n",
    "    except:\n",
    "        rd = 'Failed Run'\n",
    "    \n",
    "    return rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load city / rule settings for fast track\n",
    "def load_city_settings():\n",
    "    \n",
    "    ws_name = 'fast_track'\n",
    "\n",
    "    # open gsheet\n",
    "    ws = gs.worksheet_by_title(ws_name)\n",
    "    rd_set = ws.get_all_records()\n",
    "\n",
    "    # make data frame for manipulation\n",
    "    df_set = pd.DataFrame(rd_set)\n",
    "\n",
    "    # extract shadow cities into a new data frame\n",
    "    df_set_s = df_set[df_set['Active'] == 'Shadow']\n",
    "\n",
    "    # keep settings for enabled rules only \n",
    "    df_set = df_set[df_set['Active'] == 'Enable']\n",
    "    \n",
    "    return df_set, df_set_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to fast track courier log \n",
    "# def courier_log(df_final,gsheet_name):\n",
    "def courier_log(df_final,gsheet_key):\n",
    "    # creating log \n",
    "    df_final = df_final.applymap(encode_df)\n",
    "    # open gsheet\n",
    "    gs = gc.open_by_key(gsheet_key)\n",
    "#     gs = gc.open(gsheet_name)\n",
    "\n",
    "    if run_cycle == 1:\n",
    "        # pop old data and push new data\n",
    "        ws = gs.worksheet_by_title('today_5')\n",
    "        df_temp = ws.get_as_df(has_header=True)\n",
    "        ws = gs.worksheet_by_title('today_6')\n",
    "        ws.clear()\n",
    "        df_temp = df_temp.applymap(encode_df)\n",
    "        ws.set_dataframe(df_temp,(1,1),copy_index=False, copy_head=True, fit=True)\n",
    "\n",
    "        ws = gs.worksheet_by_title('today_4')\n",
    "        df_temp = ws.get_as_df(has_header=True)\n",
    "        ws = gs.worksheet_by_title('today_5')\n",
    "        ws.clear()\n",
    "        df_temp = df_temp.applymap(encode_df)\n",
    "        ws.set_dataframe(df_temp,(1,1),copy_index=False, copy_head=True, fit=True)\n",
    "\n",
    "        ws = gs.worksheet_by_title('today_3')\n",
    "        df_temp = ws.get_as_df(has_header=True)\n",
    "        ws = gs.worksheet_by_title('today_4')\n",
    "        ws.clear()\n",
    "        df_temp = df_temp.applymap(encode_df)\n",
    "        ws.set_dataframe(df_temp,(1,1),copy_index=False, copy_head=True, fit=True)\n",
    "\n",
    "        ws = gs.worksheet_by_title('today_2')\n",
    "        df_temp = ws.get_as_df(has_header=True)\n",
    "        ws = gs.worksheet_by_title('today_3')\n",
    "        ws.clear()\n",
    "        df_temp = df_temp.applymap(encode_df)\n",
    "        ws.set_dataframe(df_temp,(1,1),copy_index=False, copy_head=True, fit=True)\n",
    "\n",
    "        ws = gs.worksheet_by_title('today_1')\n",
    "        df_temp = ws.get_as_df(has_header=True)\n",
    "        ws = gs.worksheet_by_title('today_2')\n",
    "        ws.clear()\n",
    "        df_temp = df_temp.applymap(encode_df)\n",
    "        ws.set_dataframe(df_temp,(1,1),copy_index=False, copy_head=True, fit=True)\n",
    "\n",
    "        ws = gs.worksheet_by_title('today')\n",
    "        df_temp = ws.get_as_df(has_header=True)\n",
    "        ws = gs.worksheet_by_title('today_1')\n",
    "        ws.clear()\n",
    "        df_temp = df_temp.applymap(encode_df)\n",
    "        ws.set_dataframe(df_temp,(1,1),copy_index=False, copy_head=True, fit=True)\n",
    "\n",
    "        ws = gs.worksheet_by_title('today')\n",
    "        ws.clear()\n",
    "        ws.set_dataframe(df_final,(1,1),copy_index=False, copy_head=True, fit=True)\n",
    "\n",
    "    else: \n",
    "        ws = gs.worksheet_by_title('today')\n",
    "        df_temp = ws.get_as_df(has_header=True)\n",
    "        ws.set_dataframe(df_final,(df_temp.shape[0]+2,1),copy_index=False, copy_head=True, fit=True)\n",
    "\n",
    "    # End of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build data frames by group query rules for enabled and shadow mode rules/cities\n",
    "def rule_engine(df, df_s):\n",
    "    \n",
    "    # separate out the settings basis rule-query combination\n",
    "    df_1 = df[(df['Rule'] == 'Fraud trips (notification)') | (df['Rule'] == 'Fraud trips (immediate WL)')]\n",
    "    df_1 = df_1.append(df[(df['Rule'] == 'Failed trips (notification)') | (df['Rule'] == 'Failed trips (immediate WL)')])\n",
    "    df_1 = df_1.append(df[(df['Rule'] == 'NRO trips (notification)') | (df['Rule'] == 'NRO trips (immediate WL)')])\n",
    "\n",
    "    df_2 = df[(df['Rule'] == 'Cancels at Restaurant (notification)') | (df['Rule'] == 'Cancels at Restaurant (immediate WL)')]\n",
    "\n",
    "    df_3 = df[(df['Rule'] == 'Full Day Failures (notification)') | (df['Rule'] == 'Full Day Failures (immediate WL)')]\n",
    "\n",
    "    df_4 = df[(df['Rule'] == 'Failure at same location (notification)') | (df['Rule'] == 'Failure at same location (immediate WL)')]\n",
    "    df_4 = df_4.append(df[(df['Rule'] == 'No movement (notification)') | (df['Rule'] == 'No movement (immediate WL)')])    \n",
    "\n",
    "    df_5 = df[(df['Rule'] == 'Missing Items (notification)') | (df['Rule'] == 'Missing Items (immediate WL)')]\n",
    "    \n",
    "    # separate out the settings basis rule-query combination (for shadow mode)\n",
    "    df_s_1 = df_s[(df_s['Rule'] == 'Fraud trips (notification)') | (df_s['Rule'] == 'Fraud trips (immediate WL)')]\n",
    "    df_s_1 = df_s_1.append(df_s[(df_s['Rule'] == 'Failed trips (notification)') | (df_s['Rule'] == 'Failed trips (immediate WL)')])\n",
    "    df_s_1 = df_s_1.append(df_s[(df_s['Rule'] == 'NRO trips (notification)') | (df_s['Rule'] == 'NRO trips (immediate WL)')])\n",
    "\n",
    "    df_s_2 = df_s[(df_s['Rule'] == 'Cancels at Restaurant (notification)') | (df_s['Rule'] == 'Cancels at Restaurant (immediate WL)')]\n",
    "\n",
    "    df_s_3 = df_s[(df_s['Rule'] == 'Full Day Failures (notification)') | (df_s['Rule'] == 'Full Day Failures (immediate WL)')]\n",
    "\n",
    "    df_s_4 = df_s[(df_s['Rule'] == 'Failure at same location (notification)') | (df_s['Rule'] == 'Failure at same location (immediate WL)')]\n",
    "    df_s_4 = df_s_4.append(df_s[(df_s['Rule'] == 'No movement (notification)') | (df_s['Rule'] == 'No movement (immediate WL)')])\n",
    "\n",
    "    return df_1,df_2,df_3,df_4,df_5,df_s_1,df_s_2,df_s_3,df_s_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_status(rd,rule,time):\n",
    "\n",
    "    ws = gs.worksheet_by_title('locked_actions')\n",
    "    numRows = len(ws.get_all_values(returnas='matrix'))\n",
    "    ws.add_rows(1)\n",
    "    \n",
    "    rule_cell = \"A\" + str((numRows+1))\n",
    "    time_cell = \"B\" + str((numRows+1))\n",
    "    status_cell = \"C\" + str((numRows+1))\n",
    "    \n",
    "    ws.cell(rule_cell).value = rule\n",
    "    ws.cell(time_cell).value = time\n",
    "        \n",
    "    if (rd == \"Failed Run\" or len(rd) == 0):\n",
    "        ws.cell(status_cell).value = rule = 'Query Timeout'\n",
    "       \n",
    "    else:\n",
    "        ws.cell(status_cell).value = 'Success'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check existence of notification tag, and tag / note only for new courier partners\n",
    "def tag_notes_courier(rd):\n",
    "\n",
    "    if len(rd) <> 0:\n",
    "        for ctr in range(0,len(rd)):\n",
    "            # check for notification tag\n",
    "            t1 = tchannel.thrift(populous_service.UserService.getUserTag(rd[ctr]['driver_uuid'], rd[ctr]['tag']))\n",
    "            \n",
    "            try:\n",
    "                t2=t1.result()\n",
    "                rd[ctr]['Status'] = \"Not Actioned\"\n",
    "            except:\n",
    "                rd[ctr]['Status'] = \"Actioned\"\n",
    "                tchannel.thrift(populous_service.UserService.createUserTag(rd[ctr]['driver_uuid'], rd[ctr]['tag']))\n",
    "                tchannel.thrift(populous_service.UserService.createUserNote(rd[ctr]['driver_uuid'], rd[ctr]['note']))\n",
    "\n",
    "                if rd[ctr]['tag'].find('notification') <> -1:\n",
    "                    tchannel.thrift(populous_service.UserService.createUserTag(rd[ctr]['driver_uuid'],notification_tracking_tag))\n",
    "\n",
    "                if rd[ctr]['tag'].find('immediatewl') <> -1:\n",
    "                    tchannel.thrift(populous_service.UserService.createUserTag(rd[ctr]['driver_uuid'],waitlist_tracking_tag))\n",
    "    # return the new data frame\n",
    "    return rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10/02/2019 04:13:36 PM \u001b[93m Fetching metadata for Report EpowqPGsn \u001b[0m\n",
      "2019-10-02 16:13:36,371 querybuilder_client INFO \u001b[93m Fetching metadata for Report EpowqPGsn \u001b[0m\n",
      "10/02/2019 04:13:36 PM \u001b[92m Loaded object metadata. \u001b[0m\n",
      "2019-10-02 16:13:36,447 querybuilder_client INFO \u001b[92m Loaded object metadata. \u001b[0m\n",
      "10/02/2019 04:13:36 PM \u001b[93m Templating query for report EpowqPGsn \u001b[0m\n",
      "2019-10-02 16:13:36,451 querybuilder_client INFO \u001b[93m Templating query for report EpowqPGsn \u001b[0m\n",
      "10/02/2019 04:13:36 PM \u001b[92m Templated query successfully. \u001b[0m\n",
      "2019-10-02 16:13:36,520 querybuilder_client INFO \u001b[92m Templated query successfully. \u001b[0m\n",
      "10/02/2019 04:13:36 PM \u001b[93m [Polling] 0a7ffead-31b8-4b3b-8fca-1f9b571edcec \u001b[0m\n",
      "10/02/2019 04:13:36 PM \u001b[93m [Status] pending validation \u001b[0m\n",
      "10/02/2019 04:13:37 PM \u001b[93m [Status] in validation \u001b[0m\n",
      "10/02/2019 04:13:38 PM \u001b[93m [Status] pending execution \u001b[0m\n",
      "10/02/2019 04:13:39 PM \u001b[93m [Status] in execution \u001b[0m\n",
      "10/02/2019 04:13:39 PM \u001b[93m [External ID] f9fdc8bb-6797-40e6-aad6-9d2c6153caa9 \u001b[0m\n",
      "10/02/2019 04:13:41 PM \u001b[93m [Details] {u'queryErrorMessage': u'', u'startTimestamp': u'', u'errorMessage': u'', u'isSuccess': True, u'queryState': u'RUNNING', u'queryErrorCode': 0, u'endTimestamp': u''} \u001b[0m\n",
      "10/02/2019 04:14:56 PM \u001b[93m [Status] finished success \u001b[0m\n",
      "10/02/2019 04:14:56 PM \u001b[92m [Query Success] finished success \u001b[0m\n",
      "10/02/2019 04:15:01 PM \u001b[93m Fetching metadata for Report e5kwFFUNB \u001b[0m\n",
      "2019-10-02 16:15:01,483 querybuilder_client INFO \u001b[93m Fetching metadata for Report e5kwFFUNB \u001b[0m\n",
      "10/02/2019 04:15:01 PM \u001b[92m Loaded object metadata. \u001b[0m\n",
      "2019-10-02 16:15:01,535 querybuilder_client INFO \u001b[92m Loaded object metadata. \u001b[0m\n",
      "10/02/2019 04:15:01 PM \u001b[93m Templating query for report e5kwFFUNB \u001b[0m\n",
      "2019-10-02 16:15:01,539 querybuilder_client INFO \u001b[93m Templating query for report e5kwFFUNB \u001b[0m\n",
      "10/02/2019 04:15:01 PM \u001b[92m Templated query successfully. \u001b[0m\n",
      "2019-10-02 16:15:01,605 querybuilder_client INFO \u001b[92m Templated query successfully. \u001b[0m\n",
      "10/02/2019 04:15:01 PM \u001b[93m [Polling] 1d228a40-9b16-4e95-b683-c7b217c55765 \u001b[0m\n",
      "10/02/2019 04:15:01 PM \u001b[93m [Status] pending validation \u001b[0m\n",
      "10/02/2019 04:15:02 PM \u001b[93m [Status] in execution \u001b[0m\n",
      "10/02/2019 04:15:03 PM \u001b[93m [External ID] 2493f74a-834f-4204-bf93-4d13ef09c42d \u001b[0m\n",
      "10/02/2019 04:15:18 PM \u001b[93m [Details] {u'queryErrorMessage': u'', u'startTimestamp': u'', u'errorMessage': u'', u'isSuccess': True, u'queryState': u'RUNNING', u'aggregatePercentage': 0, u'queryErrorCode': 0, u'endTimestamp': u''} \u001b[0m\n",
      "10/02/2019 04:15:59 PM \u001b[93m [Status] finished success \u001b[0m\n",
      "10/02/2019 04:15:59 PM \u001b[92m [Query Success] finished success \u001b[0m\n",
      "/home/udocker/phoenix-worker/environments/python2/local/lib/python2.7/site-packages/unidecode/__init__.py:46: RuntimeWarning: Argument <type 'str'> is not an unicode object. Passing an encoded string will likely have unexpected results.\n",
      "  _warn_if_not_unicode(string)\n"
     ]
    }
   ],
   "source": [
    "run_fast_track = is_fast_track()\n",
    "if run_fast_track == 'Yes':\n",
    "    df, df_s = load_city_settings()\n",
    "    df_1,df_2,df_3,df_4,df_5,df_s_1,df_s_2,df_s_3,df_s_4 = rule_engine(df,df_s)\n",
    "    \n",
    "    q_1 = 'EpowqPGsn' # fraud, failed, nro\n",
    "    q_2 = '' # cancel at restaurant\n",
    "    q_3 = '' # all day failures\n",
    "    q_4 = '' # no movement, same location fails\n",
    "    q_5 = '' # missing items \n",
    "    q_6 = 'e5kwFFUNB' # cool off logic\n",
    "    \n",
    "    d_1 = 'presto'\n",
    "    d_2 = 'presto'\n",
    "    d_3 = 'presto'\n",
    "    d_4 = 'presto'\n",
    "    d_5 = 'presto'\n",
    "    d_6 = 'presto'\n",
    "    \n",
    "    from datetime import datetime, timedelta\n",
    "    datestr = str(datetime.now() - timedelta(days=56))[0:10]\n",
    "    \n",
    "    time_now = datetime.now()\n",
    "    \n",
    "    if time_now.hour < 17:\n",
    "        run_cycle = 1\n",
    "    elif time_now.hour >= 18:\n",
    "        run_cycle = 2\n",
    "      \n",
    "    rd_1 = qb_engine(df_1,q_1,d_1,datestr)\n",
    "    update_status(rd_1,'Rules # Fraud, Failed, NRO',str(datetime.now())[0:19])\n",
    "\n",
    "#     rd_2 = qb_engine(df_2,q_2,d_2,datestr)\n",
    "#     update_status(rd_2,'Rules # Cancelation at Rest',str(datetime.now())[0:19])\n",
    "    \n",
    "#     rd_3 = qb_engine(df_3,q_3,d_3,datestr)\n",
    "#     update_status(rd_3,'Rules # All day failures',str(datetime.now())[0:19])\n",
    "    \n",
    "    \n",
    "#     rd_4 = qb_engine(df_4,q_4,d_4,datestr)\n",
    "#     update_status(rd_4,'Rules # No movement, Same location fail',str(datetime.now())[0:19])\n",
    "        \n",
    "#     rd_5 = qb_engine(df_5,q_5,d_5,datestr)\n",
    "#     update_status(rd_5,'Rules # missing items',str(datetime.now())[0:19])\n",
    "    \n",
    "    rd_6 = co_engine(df,q_6,d_6,datestr)\n",
    "    update_status(rd_6,'Cool off logic',str(datetime.now())[0:19])\n",
    "\n",
    "    \n",
    "    # notification and tracking tags \n",
    "    notification_tracking_tag = 'latam_fraud_fasttrack_soft_tag'\n",
    "    waitlist_tracking_tag = 'latam_fraud_fasttrack_wl_queue'\n",
    "\n",
    "    rd_f = []\n",
    "    \n",
    "    if rd_1 <> \"Failed Run\": \n",
    "        rd_f += rd_1\n",
    "#     if rd_2 <> \"Failed Run\": \n",
    "#         rd_f += rd_2\n",
    "#     if rd_3 <> \"Failed Run\": \n",
    "#         rd_f += rd_3\n",
    "#     if rd_4 <> \"Failed Run\": \n",
    "#         rd_f += rd_4\n",
    "#     if rd_5 <> \"Failed Run\": \n",
    "#         rd_f += rd_5\n",
    "\n",
    "    #tag and add notes\n",
    "    rd_f = tag_notes_courier(rd_f)\n",
    "    \n",
    "    #add cooloff output to rd_f after tagging and actioning\n",
    "    if rd_6 <> \"Failed Run\":\n",
    "        if len(rd_6) <> 0:\n",
    "            for ctr in range(0,len(rd_6)):\n",
    "                tchannel.thrift(populous_service.UserService.createUserTag(rd_6[ctr]['driver_uuid'], rd_6[ctr]['tag']))\n",
    "                rd_6[ctr]['Status'] = \"Actioned\"\n",
    "        rd_f += rd_6\n",
    "    \n",
    "        \n",
    "    # if output from all queries is null \n",
    "    if len(rd_f) <> 0:\n",
    "        df_f = pd.DataFrame(rd_f)\n",
    "        df_f['timestamp'] = str(datetime.now())[0:19]\n",
    "        courier_log(df_f,'1lWlxD5t49uPEOj_1QOb8W2HdqqRrC_JA-qS8QzBB9gY')\n",
    "        \n",
    "    else:\n",
    "        df_f = pd.DataFrame()\n",
    "        df_f['Status'] = ''\n",
    "        df_f['city_id'] = ''\n",
    "        df_f['driver_uuid'] = ''\n",
    "        df_f['note'] = ''\n",
    "        df_f['tag'] = ''\n",
    "        df_f['timestamp'] = ''\n",
    "        df_f = df_f.append({'Status': 'Null query output', 'city_id': 'Null query output', 'driver_uuid': 'Null query output', 'note': 'Null query output', 'tag': 'Null query output', 'timestamp': str(datetime.now())[0:19]}, ignore_index=True)\n",
    "        courier_log(df_f,'1lWlxD5t49uPEOj_1QOb8W2HdqqRrC_JA-qS8QzBB9gY')\n",
    "    \n",
    "    # End of execution   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "courier_log(df_f,'1lWlxD5t49uPEOj_1QOb8W2HdqqRrC_JA-qS8QzBB9gY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 (General DS)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
